{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"aR8XKH2OhCrm","colab_type":"text"},"cell_type":"markdown","source":["Load google drive into the VM:"]},{"metadata":{"id":"xyZTRbWQBwML","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3He1E7-ZhJrr","colab_type":"text"},"cell_type":"markdown","source":["Load labels from CamVid dataset:"]},{"metadata":{"id":"uwOJn-PSx2x8","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","subdir_label_colors = \"label_colorsSorted.txt\"\n","directory = \"drive/My Drive/datasets/camvid-master/\"\n","\n","labels = dict()\n","label_ids = []\n","with open(directory + subdir_label_colors, 'r') as color_file:\n","    file = color_file.read()\n","    i = 0\n","    for line in file.split('\\n'):\n","      words = line.split()\n","      label_ids.append(words[0])\n","      labels[i] = np.array([words[1], words[2], words[3]]).astype(int)\n","      i += 1\n","#print(labels)\n","#print(label_ids)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PyYbEjcPhOs2","colab_type":"text"},"cell_type":"markdown","source":["Separate test, validation, and train data:"]},{"metadata":{"id":"Kz6sImfVFimO","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","from PIL import Image\n","import numpy as np\n","import os\n","import pickle\n","\n","directory = \"drive/My Drive/datasets/camvid-master/\"\n","subdir = \"701_StillsRaw_full/\"\n","subdir_l = \"LabeledApproved_full/\"\n","subdir_final_l = \"Labels_full/\"\n","train_test = 5\n","test_validation = 10\n","partition = {\n","    'train': [],\n","    'test': [],\n","    'validation': []\n","}\n","\n","\n","for root, dir, files in os.walk(directory + subdir):\n","  i = 0\n","  j = 0\n","  for file in files:\n","    if i % train_test == 0:\n","      partition['test'].append(file.split('.')[0])\n","    else:\n","      j += 1\n","      if j % test_validation == 0:\n","        partition['validation'].append(file.split('.')[0])\n","      else:\n","        partition['train'].append(file.split('.')[0])\n","    i += 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZaUGafI2hV3j","colab_type":"text"},"cell_type":"markdown","source":["Create new label files by replacing each pixel with corresponding class number:"]},{"metadata":{"id":"c015y9I1sbSx","colab_type":"code","colab":{}},"cell_type":"code","source":["for root, dir, files in os.walk(directory + subdir_l):\n","  for file in files:\n","    print(file)\n","    y = np.array(Image.open(directory + subdir_l + file))\n","    label = np.zeros((y.shape[0], y.shape[1]))\n","    for k, v in labels.items():\n","      label[np.where((y == np.asarray(v)).sum(-1) == 3)] = k\n","      \n","    try:\n","      os.stat(directory + subdir_final_l)\n","    except:\n","      os.mkdir(directory + subdir_final_l)\n","    pickle.dump(label, open(directory + subdir_final_l + file, 'wb'))\n","    \n","    '''\n","    for i, h in enumerate(y):\n","      for j, w in enumerate(h):\n","        for k, v in self.labels.items():\n","          if list(v) == list(y[i][j]):\n","            label[i][j] = k\n","    '''    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"XeQF9U-zhgT5","colab_type":"text"},"cell_type":"markdown","source":["Create dataset class for loading train, test, and validation data:"]},{"metadata":{"id":"ltJWk-_InYWc","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","from torch.utils import data\n","import pickle\n","\n","class Dataset(data.Dataset):\n","  def __init__(self, list_IDs, labels, transform=None):\n","    self.labels = labels\n","    self.list_IDs = list_IDs\n","    self.transform = transform\n","\n","  def __len__(self):\n","    return len(self.list_IDs)\n","\n","  def __getitem__(self, index):\n","    ID = self.list_IDs[index]\n","    X = np.array(Image.open(directory + subdir + ID + '.png'))\n","    X = np.rollaxis(X, 2)\n","    if self.transform:\n","      X = self.transform(X)\n","    label = pickle.load(open(directory + subdir_final_l + ID + '_L.png', 'rb'))\n","#     for i, h in enumerate(y):\n","    return X, label"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D5d61e8ahl0q","colab_type":"text"},"cell_type":"markdown","source":["Initialize the network with specified parameters and train and test the network:"]},{"metadata":{"id":"SQzyAuaW9kNg","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch.nn.functional as F\n","#from unet import UNet\n","from my_unet import UNet\n","import numpy as np\n","from torchsummary import summary\n","\n","batch_size = 1\n","\n","width = 960\n","height = 720\n","\n","params = {'batch_size': batch_size,\n","          'shuffle': False,\n","          'num_workers': 6}\n","\n","epochs = 1\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","training_set = Dataset(partition['train'], [])\n","training_generator = data.DataLoader(training_set, **params)\n","\n","validation_set = Dataset(partition['validation'], [])\n","validation_generator = data.DataLoader(validation_set, **params)\n","\n","test_set = Dataset(partition['test'], [])\n","test_generator = data.DataLoader(test_set, **params)\n","\n","model = UNet(n_classes=50, padding=1, batch_norm=False, kernel_size=3, max_pool_or_stride=False).to(device)\n","#model  = UNet(n_class=50).to(device)\n","optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","\n","print(summary(model, (3, height, width)))\n","train_loss = []\n","validation_loss = []\n","test_loss = []\n","accuracy = []\n","\n","\n","for epoch in range(epochs):\n","    i = 0\n","    epoch_loss = 0.0\n","    total_val_loss = 0.0\n","    total_test_loss = 0.0\n","    for x, y in training_generator:\n","      x, y = x.float() / 255.0, y.long()\n","      prediction = model(x.to(device))\n","      loss = F.cross_entropy(prediction, y.to(device))\n","      epoch_loss += loss.item()\n","      optim.zero_grad()\n","      loss.backward()\n","      optim.step()\n","      print('[%d, %d] Train loss = %.5f' %\n","          (epoch + 1, i + batch_size, loss.item()))\n","      i += batch_size\n","    train_loss.append(epoch_loss)\n","    \n","    for x, y in validation_generator:\n","      x, y = x.float() / 255.0, y.long()\n","      x, y = x.to(device), y.to(device)\n","      prediction = model(x)\n","      loss = F.cross_entropy(prediction, y)\n","      total_val_loss += loss.item()\n","    print('[%d] Validation loss = %.5f' % (epoch + 1, total_val_loss / len(validation_generator)))\n","    validation_loss.append(total_val_loss)\n","    \n","    acc = []\n","    for x, y in test_generator:\n","      x, y = x.float() / 255.0, y.long()\n","      x, y = x.to(device), y.to(device)\n","      prediction = model(x)\n","      loss = F.cross_entropy(prediction, y)\n","      total_test_loss += loss.item()\n","      acc.append(int((torch.argmax(prediction, dim=1) == y).sum()) / (width * height))\n","    print('[%d] Test loss = %.5f' % (epoch + 1, total_test_loss / len(test_generator)))\n","    test_loss.append(total_test_loss / len(test_generator))\n","    print('[%d] Test acc = %.5f' % (epoch + 1, np.array(acc).mean()))\n","    accuracy.append(np.array(acc).mean())\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"thuZohn6h19d","colab_type":"text"},"cell_type":"markdown","source":["(For part I in section 1 of the project) Give a random image to the network and compare original label image with predicted image: "]},{"metadata":{"id":"MTko9Ocz5gFT","colab_type":"code","colab":{}},"cell_type":"code","source":["from PIL import Image\n","import pickle\n","\n","f = np.zeros((height, width, 3))\n","for i, h in enumerate(y[0]):\n","  for j, w in enumerate(h):\n","    for k, v in labels.items():\n","      if k == w:\n","        f[i][j] = v\n","\n","pickle.dump(f, open(directory + 'test_image_orig.p', 'wb'))\n","f = Image.fromarray(np.array(f).astype('uint8'))\n","f.save(directory + 'test_img_orig.png')\n","\n","y = np.rollaxis(prediction[0], 2)\n","\n","pickle.dump(y, open(directory + 'test_image_pred.p', 'wb'))\n","q = np.zeros((height, width, 3))\n","for i, h in enumerate(y):\n","      for j, w in enumerate(h):\n","        for k, v in labels.items():\n","          if k == torch.argmax(w):\n","            q[i][j] = k\n","\n","q = Image.fromarray(np.array(q).astype('uint8'))\n","q.save(directory + 'test_img_pred.png')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TVcM6bgriJIG","colab_type":"text"},"cell_type":"markdown","source":["Draw loss and accuracy diagram:"]},{"metadata":{"id":"mUSo9OX8FDVv","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot([i + 1 for i in range(epochs)], [t / len(training_generator) for t in train_loss], marker='o')\n","plt.plot([i + 1 for i in range(epochs)], test_loss, marker='o')\n","plt.plot([i + 1 for i in range(epochs)], [t / len(validation_generator) for t in validation_loss], marker='o')\n","plt.title('Changes in loss function')\n","plt.xlabel('Epoch')\n","plt.ylabel('Cross Entropy Loss')\n","#plt.figure()\n","plt.savefig(directory + 'loss-4.jpg')\n","plt.show()\n","\n","plt.plot([i + 1 for i in range(epochs)], accuracy, marker='o', color='red')\n","plt.title('Changes in accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('accuracy')\n","#plt.figure()\n","plt.savefig(directory + 'acc-4.jpg')\n","plt.show()\n"],"execution_count":0,"outputs":[]}]}